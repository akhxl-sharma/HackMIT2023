{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.decomposition import FastICA\n",
    "import mne \n",
    "import pickle\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = pd.read_pickle('/Users/akhil/Downloads/HackMIT2023/EEG Stress Dataset/Horror Video PKL/1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['# TIME_STAMP_s', 'TIME_STAMP_ms', 'OR_TIME_STAMP_s',\n",
       "       'OR_TIME_STAMP_ms', 'COUNTER', 'INTERPOLATED', 'AF3', 'T7', 'Pz', 'T8',\n",
       "       'AF4', 'RAW_CQ', 'BATTERY', 'BATTERY_PERCENT', 'MarkerIndex',\n",
       "       'MarkerType', 'MarkerValueInt', 'MARKER_HARDWARE', 'CQ_AF3', 'CQ_T7',\n",
       "       'CQ_Pz', 'CQ_T8', 'CQ_AF4', 'CQ_OVERALL', 'EQ_SampleRateQua',\n",
       "       'EQ_OVERALL', 'EQ_AF3', 'EQ_T7', 'EQ_Pz', 'EQ_T8', 'EQ_AF4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = df_h[['TIME_STAMP_ms', 'AF3', 'T7', 'Pz', 'T8', 'AF4',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_STAMP_ms</th>\n",
       "      <th>AF3</th>\n",
       "      <th>T7</th>\n",
       "      <th>Pz</th>\n",
       "      <th>T8</th>\n",
       "      <th>AF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.005156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.005116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.005149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.005185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26747</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.004758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26748</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.004746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26749</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.004673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26750</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26751</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.004553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26752 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_STAMP_ms       AF3        T7        Pz        T8       AF4\n",
       "0           0.000000  0.005153  0.004858  0.005128  0.004988  0.005156\n",
       "1           0.000008  0.005186  0.004779  0.005088  0.005026  0.005116\n",
       "2           0.000016  0.005189  0.004847  0.005140  0.004995  0.005149\n",
       "3           0.000023  0.005168  0.004845  0.005175  0.004990  0.005185\n",
       "4           0.000031  0.005206  0.004784  0.005159  0.005075  0.005193\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "26747       0.000016  0.004783  0.003450  0.004641  0.004478  0.004758\n",
       "26748       0.000024  0.004785  0.003472  0.004639  0.004481  0.004746\n",
       "26749       0.000032  0.004725  0.003440  0.004581  0.004456  0.004673\n",
       "26750       0.000040  0.004663  0.003458  0.004516  0.004430  0.004624\n",
       "26751       0.000048  0.004605  0.003508  0.004448  0.004349  0.004553\n",
       "\n",
       "[26752 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the EEG data as a NumPy array\n",
    "eeg_data = df_h[['AF3', 'T7', 'Pz', 'T8', 'AF4']].values\n",
    "\n",
    "# Initialize and fit the ICA model\n",
    "ica = FastICA(n_components=5, random_state=0)  # Specify the number of components\n",
    "ica.fit(eeg_data)\n",
    "\n",
    "# Get the independent components (ICs) and the mixing matrix\n",
    "ICs = ica.components_\n",
    "mixing_matrix = ica.mixing_\n",
    "\n",
    "# Apply ICA to your EEG data to separate the independent components\n",
    "independent_components = ica.transform(eeg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42799958, -0.67504978, -0.46637124,  0.56794745,  0.84844319],\n",
       "       [-0.5638822 , -0.72555624,  0.09135164,  0.19704248,  1.0266184 ],\n",
       "       [-0.32225275, -0.66853824, -0.43008151,  0.53932154,  0.91576422],\n",
       "       ...,\n",
       "       [ 0.32429578, -2.07040918,  0.17529434, -0.14523358, -0.30264415],\n",
       "       [ 0.62838415, -1.97183161,  0.3363129 , -0.25330503, -0.30146378],\n",
       "       [ 0.40855945, -1.75916099,  0.22679522, -0.29843042, -0.32829755]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5, kernLength = 64, F1 = 8, D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \"\"\" \n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.     \n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D ' 'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same', input_shape = (Chans, Samples, 1), use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, depth_multiplier = D, depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16), use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense', kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def EEGNet_SSVEP(nb_classes = 12, Chans = 8, Samples = 256, dropoutRate = 0.5, kernLength = 256, F1 = 96, D = 1, F2 = 96, dropoutType = 'Dropout'):\n",
    "    \"\"\" SSVEP Variant of EEGNet, as used in [1]. \n",
    "\n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer\n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution.\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "      \n",
    "      \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D ' 'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same', input_shape = (Chans, Samples, 1), use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, depth_multiplier = D, depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16), use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "def EEGNet_old(nb_classes, Chans = 64, Samples = 128, regRate = 0.0001, dropoutRate = 0.25, kernels = [(2, 32), (8, 4)], strides = (2, 4)):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        \n",
    "        nb_classes     : total number of final categories\n",
    "        Chans, Samples : number of EEG channels and samples, respectively\n",
    "        regRate        : regularization rate for L1 and L2 regularizations\n",
    "        dropoutRate    : dropout fraction\n",
    "        kernels        : the 2nd and 3rd layer kernel dimensions (default is the [2, 32] x [8, 4] configuration)\n",
    "        strides        : the stride size (note that this replaces the max-pool used in the original paper)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples))\n",
    "    layer1       = Conv2D(16, (Chans, 1), input_shape=(Chans, Samples, 1), kernel_regularizer = l1_l2(l1=regRate, l2=regRate))(input_main)\n",
    "    layer1       = BatchNormalization()(layer1)\n",
    "    layer1       = Activation('elu')(layer1)\n",
    "    layer1       = Dropout(dropoutRate)(layer1)\n",
    "    \n",
    "    permute_dims = 2, 1, 3\n",
    "    permute1     = Permute(permute_dims)(layer1)\n",
    "    \n",
    "    layer2       = Conv2D(4, kernels[0], padding = 'same', kernel_regularizer=l1_l2(l1=0.0, l2=regRate), strides = strides)(permute1)\n",
    "    layer2       = BatchNormalization()(layer2)\n",
    "    layer2       = Activation('elu')(layer2)\n",
    "    layer2       = Dropout(dropoutRate)(layer2)\n",
    "    \n",
    "    layer3       = Conv2D(4, kernels[1], padding = 'same', kernel_regularizer=l1_l2(l1=0.0, l2=regRate), strides = strides)(layer2)\n",
    "    layer3       = BatchNormalization()(layer3)\n",
    "    layer3       = Activation('elu')(layer3)\n",
    "    layer3       = Dropout(dropoutRate)(layer3)\n",
    "    \n",
    "    flatten      = Flatten(name = 'flatten')(layer3)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "\n",
    "# LOOK AT THIS \n",
    "def DeepConvNet(nb_classes, Chans = 64, Samples = 256, dropoutRate = 0.5):\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), input_shape=(Chans, Samples, 1), kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(25, (Chans, 1), kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "    block2       = Conv2D(50, (1, 5), kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5), kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5), kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "\n",
    "# need these for ShallowConvNet\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "\n",
    "def ShallowConvNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n",
    "    \n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(40, (1, 13), input_shape=(Chans, Samples, 1), kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(40, (Chans, 1), use_bias=False, kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n",
    "    block1       = Activation(log)(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
